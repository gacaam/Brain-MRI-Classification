{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699a3763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 15:54:22.587654: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# import os\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e51dad",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6002b7de",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d1af29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 184\n",
    "img_width = 216\n",
    "img_size = (img_height, img_width)\n",
    "img_shape = img_size + (3,)\n",
    "ds_path = \"/drive0-storage/Gracia/dataset_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec53fedf",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bbcb315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 15:54:24.574646: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-09 15:54:25.121855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7910 MB memory:  -> device: 0, name: A100-SXM4-40GB MIG 2g.10gb, pci bus id: 0000:90:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21408 files belonging to 3 classes.\n",
      "Using 17127 files for training.\n",
      "Found 21408 files belonging to 3 classes.\n",
      "Using 4281 files for validation.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    train_ds = image_dataset_from_directory(ds_path,\n",
    "                                        validation_split = 0.2,\n",
    "                                        subset = \"training\",\n",
    "                                        seed = 123,\n",
    "                                        image_size = img_size,\n",
    "                                        batch_size = batch_size)\n",
    "    \n",
    "    val_ds = image_dataset_from_directory(ds_path,\n",
    "                                      validation_split = 0.2,\n",
    "                                      subset = \"validation\",\n",
    "                                      seed = 123,\n",
    "                                      image_size = img_size,\n",
    "                                      batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ef57af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.rmdir(\"/drive0-storage/Gracia/dataset/.ipynb_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9589c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bipolar_disorder', 'healthy_controls', 'schizophrenia']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e62e45",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da2743d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "    test_dataset = val_ds.take(val_batches // 2)\n",
    "    validation_dataset = val_ds.skip(val_batches // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d968112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buffered prefetching\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    train_dataset = train_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size = AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a518689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 184, 216, 3)\n",
      "<dtype: 'float32'>\n",
      "0.0 248.0\n"
     ]
    }
   ],
   "source": [
    "for images in train_ds.take(1):\n",
    "    img = images[0]\n",
    "    print(img.shape)  \n",
    "    print(img.dtype)  \n",
    "    print(np.min(img),np.max(img))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e24a0e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d9088",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "442ef645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 5\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten the output and create fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "381cb0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    vgg16 = build_vgg16()\n",
    "\n",
    "    # add rescale layer, chain model\n",
    "    rescale = tf.keras.layers.Rescaling(1./255)\n",
    "    inputs = tf.keras.Input(shape = img_shape)\n",
    "    x = rescale(inputs)\n",
    "    outputs = vgg16(x)\n",
    "    model = tf.keras.Model(inputs,outputs) \n",
    "    \n",
    "    # compile model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0af914",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d35b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback function\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.95):\n",
    "            print(\"\\nReached 95% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e199df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-09 15:54:31.209406: I tensorflow/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-06-09 15:54:32.497949: I tensorflow/stream_executor/cuda/cuda_blas.cc:1633] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 165s 300ms/step - loss: 1.0010 - accuracy: 0.5582 - val_loss: 1.0056 - val_accuracy: 0.5433\n",
      "Epoch 2/8\n",
      "536/536 [==============================] - 159s 296ms/step - loss: 0.9966 - accuracy: 0.5583 - val_loss: 1.0051 - val_accuracy: 0.5438\n",
      "Epoch 3/8\n",
      "536/536 [==============================] - 158s 295ms/step - loss: 0.9939 - accuracy: 0.5583 - val_loss: 1.0018 - val_accuracy: 0.5461\n",
      "Epoch 4/8\n",
      "536/536 [==============================] - 159s 296ms/step - loss: 0.9891 - accuracy: 0.5583 - val_loss: 0.9937 - val_accuracy: 0.5414\n",
      "Epoch 5/8\n",
      "536/536 [==============================] - 158s 295ms/step - loss: 0.9614 - accuracy: 0.5655 - val_loss: 0.9596 - val_accuracy: 0.5676\n",
      "Epoch 6/8\n",
      "536/536 [==============================] - 159s 296ms/step - loss: 0.9051 - accuracy: 0.5959 - val_loss: 0.8993 - val_accuracy: 0.6013\n",
      "Epoch 7/8\n",
      "536/536 [==============================] - 158s 295ms/step - loss: 0.8734 - accuracy: 0.6096 - val_loss: 0.9259 - val_accuracy: 0.5934\n",
      "Epoch 8/8\n",
      "536/536 [==============================] - 158s 295ms/step - loss: 0.8462 - accuracy: 0.6259 - val_loss: 0.8451 - val_accuracy: 0.6261\n"
     ]
    }
   ],
   "source": [
    "## batch 16, optimizer adam, lr 1e-5\n",
    "EPOCH = 8\n",
    "\n",
    "history_1 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 16)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0054808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 5s 79ms/step - loss: 0.5382 - accuracy: 0.7850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.5381730794906616, 'accuracy': 0.784981369972229}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96a9cdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "536/536 [==============================] - 161s 299ms/step - loss: 0.9998 - accuracy: 0.5581 - val_loss: 1.0117 - val_accuracy: 0.5363\n",
      "Epoch 2/8\n",
      "536/536 [==============================] - 160s 299ms/step - loss: 0.9959 - accuracy: 0.5583 - val_loss: 1.0079 - val_accuracy: 0.5405\n",
      "Epoch 3/8\n",
      "536/536 [==============================] - 161s 300ms/step - loss: 0.9939 - accuracy: 0.5583 - val_loss: 1.0018 - val_accuracy: 0.5438\n",
      "Epoch 4/8\n",
      "536/536 [==============================] - 161s 300ms/step - loss: 0.9877 - accuracy: 0.5583 - val_loss: 0.9935 - val_accuracy: 0.5475\n",
      "Epoch 5/8\n",
      "536/536 [==============================] - 160s 299ms/step - loss: 0.9528 - accuracy: 0.5697 - val_loss: 0.9408 - val_accuracy: 0.5891\n",
      "Epoch 6/8\n",
      "536/536 [==============================] - 160s 299ms/step - loss: 0.9074 - accuracy: 0.5932 - val_loss: 0.9027 - val_accuracy: 0.5873\n",
      "Epoch 7/8\n",
      "536/536 [==============================] - 160s 299ms/step - loss: 0.8816 - accuracy: 0.6042 - val_loss: 0.8829 - val_accuracy: 0.6046\n",
      "Epoch 8/8\n",
      "536/536 [==============================] - 160s 299ms/step - loss: 0.8515 - accuracy: 0.6200 - val_loss: 0.8471 - val_accuracy: 0.6252\n"
     ]
    }
   ],
   "source": [
    "## batch 32, optimizer adam, lr 1e-5\n",
    "EPOCH = 8\n",
    "\n",
    "history_2 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 32)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0004694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67/67 [==============================] - 4s 64ms/step - loss: 0.8444 - accuracy: 0.6236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.8443752527236938, 'accuracy': 0.6236007213592529}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb71b7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      " 44/536 [=>............................] - ETA: 2:21 - loss: 1.0287 - accuracy: 0.5547"
     ]
    }
   ],
   "source": [
    "## batch 64, optimizer adam, lr 1e-5\n",
    "EPOCH = 8\n",
    "\n",
    "history_3 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 64)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd98f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c87e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 16, optimizer adam, lr 1e-4\n",
    "EPOCH = 8\n",
    "\n",
    "history_4 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 16)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cbf791",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 32, optimizer adam, lr 1e-4\n",
    "EPOCH = 8\n",
    "\n",
    "history_5 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 32)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1af4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdaad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 64, optimizer adam, lr 1e-4\n",
    "EPOCH = 8\n",
    "\n",
    "history_6 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 64)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07bc26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0132d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 16, optimizer adam, lr 1e-3\n",
    "EPOCH = 8\n",
    "\n",
    "history_7 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 16)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad0ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573553a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 32, optimizer adam, lr 1e-3\n",
    "EPOCH = 8\n",
    "\n",
    "history_8 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 32)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faaceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 64, optimizer adam, lr 1e-3\n",
    "EPOCH = 8\n",
    "\n",
    "history_9 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 64)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90bb2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e9f222",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 16, optimizer sgd, lr 1e-5\n",
    "EPOCH = 8\n",
    "\n",
    "history_10 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a36bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 32, optimizer sgd, lr 1e-5\n",
    "EPOCH = 8\n",
    "\n",
    "history_11 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60009e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 64, optimizer sgd, lr 1e-5\n",
    "EPOCH = 8\n",
    "\n",
    "history_12 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71b8df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 16, optimizer sgd, lr 1e-4\n",
    "EPOCH = 8\n",
    "\n",
    "history_13 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5db1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 32, optimizer sgd, lr 1e-4\n",
    "EPOCH = 8\n",
    "\n",
    "history_14 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3aaac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 64, optimizer sgd, lr 1e-4\n",
    "EPOCH = 8\n",
    "\n",
    "history_15 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba8dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 16, optimizer sgd, lr 1e-3\n",
    "EPOCH = 8\n",
    "\n",
    "history_16 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99400e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 32, optimizer sgd, lr 1e-3\n",
    "EPOCH = 8\n",
    "\n",
    "history_17 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## batch 64, optimizer sgd, lr 1e-3\n",
    "EPOCH = 8\n",
    "\n",
    "history_18 = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH)\n",
    "#             callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3994c0e2",
   "metadata": {},
   "source": [
    "### Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcde6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# training and validation accuracy\n",
    "acc = history_1.history['accuracy']\n",
    "val_acc = history_1.history['val_accuracy']\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Accuracy', size=15, fontweight='bold')\n",
    "\n",
    "# training and validation loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Loss', size=15, fontweight='bold')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
