{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "# import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758c3d57",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5976a890",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef51ba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 184\n",
    "img_width = 216\n",
    "img_size = (img_height, img_width)\n",
    "img_shape = img_size + (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48fde56",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d301a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "train_path = \"./dataset_4/training\"\n",
    "val_path = \"./dataset_4/validation\"\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    train_ds = image_dataset_from_directory(train_path,\n",
    "                                        seed = 123,\n",
    "                                        image_size = img_size,\n",
    "                                        batch_size = batch_size)\n",
    "    \n",
    "    val_ds = image_dataset_from_directory(val_path,\n",
    "                                      seed = 456,\n",
    "                                      image_size = img_size,\n",
    "                                      batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec84ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.rmdir(\"/drive0-storage/Gracia/dataset_1/.ipynb_checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c8d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526ffc9a",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    val_batches = tf.data.experimental.cardinality(val_ds)\n",
    "    test_dataset = val_ds.take(val_batches // 2)\n",
    "    validation_dataset = val_ds.skip(val_batches // 2)\n",
    "    \n",
    "    # Buffered prefetching\n",
    "    train_dataset = train_ds.prefetch(buffer_size = AUTOTUNE)\n",
    "    validation_dataset = validation_dataset.prefetch(buffer_size = AUTOTUNE)\n",
    "    test_dataset = test_dataset.prefetch(buffer_size = AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc58e264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(validation_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2c4cb6",
   "metadata": {},
   "source": [
    "## Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff02b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Block 1\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=img_shape))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Block 5\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # Flatten the output and create fully connected layers\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))  \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4622d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"GPU\"):\n",
    "    model = build_vgg16()\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate = 1e-5),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits = False),\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7422073",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc8051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback function\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('accuracy')>0.99):\n",
    "            print(\"\\nReached 99% accuracy, cancelling training\")\n",
    "            self.model.stop_training = True\n",
    "            \n",
    "callbacks = myCallback()\n",
    "save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "checkpoints_cb = tf.keras.callbacks.ModelCheckpoint('./cnn1_checkpoints', options=save_locally)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da4668",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 30\n",
    "\n",
    "history = model.fit(\n",
    "            train_dataset,\n",
    "            validation_data = validation_dataset,\n",
    "            epochs = EPOCH,\n",
    "            batch_size = 32,\n",
    "            callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cb4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./models/cnn1_14epoch.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a153c",
   "metadata": {},
   "source": [
    "### Training evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd21a19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# training and validation accuracy\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "# plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Accuracy', size=15, fontweight='bold')\n",
    "\n",
    "# training and validation loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epoch')\n",
    "# plt.ylim([0,1.0])\n",
    "plt.title('Loss', size=15, fontweight='bold')\n",
    "\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486507bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ba51ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75166cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe749f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e97348",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaa3890",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cbbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = []  # predicted labels\n",
    "true = []  # true labels\n",
    "\n",
    "for image_batch, label_batch in test_dataset:  \n",
    "    true.append(label_batch)\n",
    "    prediction = model.predict(image_batch, verbose=0)\n",
    "    predicted.append(np.argmax(prediction, axis=-1))\n",
    "\n",
    "# convert labels into tensors\n",
    "true_labels = tf.concat([item for item in true], axis=0)\n",
    "predicted_labels = tf.concat([item for item in predicted], axis=0)\n",
    "\n",
    "cf_matrix = confusion_matrix(true_labels, predicted_labels, normalize='true')\n",
    "\n",
    "# plot confusion  matrix\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = fig.add_subplot(111)\n",
    "sns.heatmap(cf_matrix, \n",
    "            annot=True)\n",
    "ax.xaxis.set_ticklabels(class_names)\n",
    "ax.yaxis.set_ticklabels(class_names)\n",
    "plt.xlabel('Predicted Label', labelpad=15, size=12, fontweight='bold')\n",
    "plt.ylabel('True Label', labelpad=15, size=12, fontweight='bold')\n",
    "plt.title('Confusion Matrix', size=15, fontweight='bold')\n",
    "plt.savefig('./CNN1_cm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
    "sensitivity = recall_score(true_labels, predicted_labels, average='weighted')\n",
    "specificity = []\n",
    "for i in range(num_classes):\n",
    "    true_negatives = np.sum(np.delete(np.delete(cf_matrix, i, axis=0), i, axis=1))\n",
    "    false_positives = np.sum(cf_matrix[:, i]) - cf_matrix[i, i]\n",
    "    specificity.append(true_negatives / (true_negatives + false_positives))\n",
    "\n",
    "# Calculate average specificity\n",
    "average_specificity = np.mean(specificity)\n",
    "\n",
    "print(\"Accuracy:\", result[1])\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"Specificity:\", average_specificity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
