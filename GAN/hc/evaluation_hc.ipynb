{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df3955d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 03:19:09.683110: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80108c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(data, obj):\n",
    "    print(f\"\\n{obj} Information\")\n",
    "    print(f\"data type: {data.dtype}\")\n",
    "    print(f\"min: {np.min(data)}\\nmax: {np.max(data)}\")\n",
    "    print(f\"shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fded880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 03:19:12.024934: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-07 03:19:12.682855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7647 MB memory:  -> device: 0, name: A100-SXM4-40GB MIG 2g.10gb, pci bus id: 0000:90:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11900 files belonging to 1 classes.\n",
      "\n",
      "Initial Real Image Information\n",
      "data type: <dtype: 'float32'>\n",
      "min: 0.0\n",
      "max: 247.0\n",
      "shape: (184, 216, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "img_height = 184\n",
    "img_width = 216\n",
    "img_size = (img_height, img_width)\n",
    "img_shape = img_size + (3,)\n",
    "\n",
    "images_path = \"/drive0-storage/Gracia/dataset/hc\"\n",
    "with tf.device(\"CPU\"):\n",
    "    real_images = image_dataset_from_directory(images_path,\n",
    "                                               image_size = img_size,\n",
    "                                               batch_size = batch_size,\n",
    "                                               seed = 123)\n",
    "\n",
    "    for images, labels in real_images.take(1):\n",
    "        for i in range(1):\n",
    "            sample = images[i]\n",
    "            print_data_info(sample, \"Initial Real Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ab7e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess(image, label):\n",
    "#     image = tf.image.resize(299,299,3)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    return image\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    real_images = (\n",
    "        real_images\n",
    "        .shuffle(buffer_size = BUFFER_SIZE)\n",
    "        .map(preprocess, num_parallel_calls=AUTOTUNE))\n",
    "    \n",
    "#     n = int(input('number of batch: '))\n",
    "    n = 25\n",
    "    images = real_images.take(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "663780a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained InceptionV3 model\n",
    "with tf.device(\"CPU\"):\n",
    "    inception_model = tf.keras.models.load_model('../inception_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23211005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(23*27*512, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((23, 27, 512)))\n",
    "    assert model.output_shape == (None, 23, 27, 512) \n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 46, 54, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 92, 108, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 184, 216, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (4, 4), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 184, 216, 1)\n",
    "\n",
    "    return model\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[184, 216, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    generator = make_generator_model()\n",
    "    discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78bf38c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceae8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = batch_size*n\n",
    "\n",
    "def preprocess_prediction(image):\n",
    "#     image = tf.image.grayscale_to_rgb(image)\n",
    "#     image = tf.image.resize(images, (299,299,3))\n",
    "    image = image/2 + 0.5\n",
    "    image *= 255\n",
    "    return image\n",
    "\n",
    "def get_features():\n",
    "    with tf.device(\"CPU\"):\n",
    "        seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "        predictions = generator(seed, training=False)\n",
    "        generated_images = preprocess_prediction(predictions)\n",
    "\n",
    "#         print_data_info(generated_images, \"Preprocessed Generated Images\")\n",
    "#         for image in real_images.take(1):\n",
    "#             print_data_info(image, \"Preprocessed Real Images\")\n",
    "\n",
    "        # calculate features from inception model prediction\n",
    "        generated_features = inception_model.predict(generated_images)\n",
    "        real_features = inception_model.predict(images)\n",
    "    return generated_features, real_features\n",
    "\n",
    "\n",
    "def calculate_fid_score(real_features, generated_features):\n",
    "    # Calculate the mean of the real and generated features\n",
    "    mean_real = np.mean(real_features, axis=0)\n",
    "    mean_generated = np.mean(generated_features, axis=0)\n",
    "\n",
    "    # Calculate the covariance matrices of the real and generated features\n",
    "    cov_real = np.cov(real_features, rowvar=False)\n",
    "    cov_generated = np.cov(generated_features, rowvar=False)\n",
    "\n",
    "    # Calculate the squared Euclidean distance between the mean feature vectors\n",
    "    distance = np.sum((mean_real - mean_generated) ** 2)\n",
    "\n",
    "    # Calculate the square root of the product of the covariance matrices\n",
    "    cov_sqrt = sqrtm(cov_real.dot(cov_generated))\n",
    "\n",
    "    # Check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(cov_sqrt):\n",
    "        cov_sqrt = cov_sqrt.real\n",
    "    \n",
    "    # Calculate the FID score\n",
    "    fid_score = distance + np.trace(cov_real + cov_generated - 2 * cov_sqrt)\n",
    "\n",
    "    return fid_score\n",
    "\n",
    "def calculate_inception_score(generated_features):\n",
    "    # Calculate the marginal distribution of class probabilities\n",
    "    marginal_probs = np.mean(generated_features, axis=0)\n",
    "\n",
    "    # Calculate the conditional distribution of class probabilities given generated images\n",
    "    conditional_probs = generated_features / np.sum(generated_features, axis=1, keepdims=True)\n",
    "\n",
    "    # Reshape the marginal_probs array to match the shape of conditional_probs\n",
    "    marginal_probs_reshaped = np.tile(marginal_probs, (conditional_probs.shape[0], 1))\n",
    "\n",
    "    # Calculate the KL-divergence between the marginal and conditional distributions\n",
    "    kl_divergence = entropy(marginal_probs_reshaped.T, conditional_probs.T)\n",
    "\n",
    "    # Calculate the Inception Score as the exponential of the mean KL-divergence\n",
    "    inception_score = np.exp(np.mean(kl_divergence))\n",
    "\n",
    "    return inception_score\n",
    "\n",
    "def restore_specific_checkpoint(index):\n",
    "    ckpt_path = f\"./training_checkpoints/ckpt-{index}\"\n",
    "    checkpoint.restore(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ae689a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 4s 352ms/step\n",
      "25/25 [==============================] - 6s 130ms/step\n",
      "8/8 [==============================] - 3s 347ms/step\n",
      "25/25 [==============================] - 5s 126ms/step\n",
      "8/8 [==============================] - 3s 340ms/step\n",
      "25/25 [==============================] - 5s 130ms/step\n",
      "8/8 [==============================] - 3s 346ms/step\n",
      "25/25 [==============================] - 5s 129ms/step\n",
      "8/8 [==============================] - 3s 314ms/step\n",
      "25/25 [==============================] - 4s 110ms/step\n",
      "8/8 [==============================] - 2s 288ms/step\n",
      "25/25 [==============================] - 4s 109ms/step\n",
      "8/8 [==============================] - 2s 292ms/step\n",
      "25/25 [==============================] - 4s 110ms/step\n",
      "8/8 [==============================] - 2s 289ms/step\n",
      "25/25 [==============================] - 4s 110ms/step\n",
      "8/8 [==============================] - 2s 288ms/step\n",
      "25/25 [==============================] - 4s 111ms/step\n",
      "8/8 [==============================] - 2s 298ms/step\n",
      "25/25 [==============================] - 5s 110ms/step\n",
      "8/8 [==============================] - 2s 298ms/step\n",
      "25/25 [==============================] - 4s 116ms/step\n",
      "8/8 [==============================] - 2s 295ms/step\n",
      "25/25 [==============================] - 4s 110ms/step\n",
      "8/8 [==============================] - 3s 293ms/step\n",
      "25/25 [==============================] - 4s 109ms/step\n"
     ]
    }
   ],
   "source": [
    "FID = []\n",
    "inception_scores = []\n",
    "epochs = np.arange(240,601,30)\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    for epoch in epochs:\n",
    "        checkpoint_idx = int(epoch/15)\n",
    "        restore_specific_checkpoint(checkpoint_idx)\n",
    "        generated_features, real_features = get_features()\n",
    "        inception_score = calculate_inception_score(generated_features)\n",
    "        fid_score = calculate_fid_score(real_features, generated_features)\n",
    "        inception_scores.append(inception_score)\n",
    "        FID.append(fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c712794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>FID</th>\n",
       "      <th>Inception Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>240</td>\n",
       "      <td>16</td>\n",
       "      <td>0.225032</td>\n",
       "      <td>3.140674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>270</td>\n",
       "      <td>18</td>\n",
       "      <td>0.349115</td>\n",
       "      <td>3.310441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.135338</td>\n",
       "      <td>2.506701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>330</td>\n",
       "      <td>22</td>\n",
       "      <td>0.186628</td>\n",
       "      <td>2.785650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>24</td>\n",
       "      <td>0.240803</td>\n",
       "      <td>3.279118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>390</td>\n",
       "      <td>26</td>\n",
       "      <td>0.156303</td>\n",
       "      <td>2.840909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>420</td>\n",
       "      <td>28</td>\n",
       "      <td>0.176571</td>\n",
       "      <td>2.496289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>450</td>\n",
       "      <td>30</td>\n",
       "      <td>0.150915</td>\n",
       "      <td>2.784421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>480</td>\n",
       "      <td>32</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>2.259897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>510</td>\n",
       "      <td>34</td>\n",
       "      <td>0.140073</td>\n",
       "      <td>2.361352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>540</td>\n",
       "      <td>36</td>\n",
       "      <td>0.271030</td>\n",
       "      <td>2.909958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>570</td>\n",
       "      <td>38</td>\n",
       "      <td>0.229984</td>\n",
       "      <td>2.600571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>600</td>\n",
       "      <td>40</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>2.394411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  checkpoint       FID  Inception Score\n",
       "0     240          16  0.225032         3.140674\n",
       "1     270          18  0.349115         3.310441\n",
       "2     300          20  0.135338         2.506701\n",
       "3     330          22  0.186628         2.785650\n",
       "4     360          24  0.240803         3.279118\n",
       "5     390          26  0.156303         2.840909\n",
       "6     420          28  0.176571         2.496289\n",
       "7     450          30  0.150915         2.784421\n",
       "8     480          32  0.096489         2.259897\n",
       "9     510          34  0.140073         2.361352\n",
       "10    540          36  0.271030         2.909958\n",
       "11    570          38  0.229984         2.600571\n",
       "12    600          40  0.101288         2.394411"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'epoch' : epochs,\n",
    "                   'checkpoint' : (epochs/15).astype('uint8'),\n",
    "                   'FID' : FID,\n",
    "                   'Inception Score':inception_scores})\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
