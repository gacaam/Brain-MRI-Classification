{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24460927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 05:49:13.632591: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "687f174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(data, obj):\n",
    "    print(f\"\\n{obj} Information\")\n",
    "    print(f\"data type: {data.dtype}\")\n",
    "    print(f\"min: {np.min(data)}\\nmax: {np.max(data)}\")\n",
    "    print(f\"shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78943d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 05:49:15.799872: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 05:49:16.376938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7910 MB memory:  -> device: 0, name: A100-SXM4-40GB MIG 2g.10gb, pci bus id: 0000:90:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11900 files belonging to 1 classes.\n",
      "\n",
      "Initial Real Image Information\n",
      "data type: <dtype: 'float32'>\n",
      "min: 0.0\n",
      "max: 247.0\n",
      "shape: (184, 216, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "img_height = 184\n",
    "img_width = 216\n",
    "img_size = (img_height, img_width)\n",
    "img_shape = img_size + (3,)\n",
    "\n",
    "images_path = \"/drive0-storage/Gracia/dataset/hc\"\n",
    "with tf.device(\"CPU\"):\n",
    "    real_images = image_dataset_from_directory(images_path,\n",
    "                                               image_size = img_size,\n",
    "                                               batch_size = batch_size,\n",
    "                                               seed = 123)\n",
    "\n",
    "    for images, labels in real_images.take(1):\n",
    "        for i in range(1):\n",
    "            sample = images[i]\n",
    "            print_data_info(sample, \"Initial Real Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bb9ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess(image, label):\n",
    "#     image = tf.image.resize(299,299,3)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    return image\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    real_images = (\n",
    "        real_images\n",
    "        .shuffle(buffer_size = BUFFER_SIZE)\n",
    "        .map(preprocess, num_parallel_calls=AUTOTUNE))\n",
    "    \n",
    "#     n = int(input('number of batch: '))\n",
    "    n = 10\n",
    "    images = real_images.take(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "511c47a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained InceptionV3 model\n",
    "with tf.device(\"CPU\"):\n",
    "    inception_model = tf.keras.models.load_model('transfer_learning_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "596a1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(23*27*512, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((23, 27, 512)))\n",
    "    assert model.output_shape == (None, 23, 27, 512) \n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 46, 54, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 92, 108, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 184, 216, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (4, 4), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 184, 216, 1)\n",
    "\n",
    "    return model\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[184, 216, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    generator = make_generator_model()\n",
    "    discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c28d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f4f8030fc10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d928c501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessed Generated Images Information\n",
      "data type: <dtype: 'float32'>\n",
      "min: 0.0\n",
      "max: 253.58407592773438\n",
      "shape: (100, 184, 216, 1)\n",
      "\n",
      "Preprocessed Real Images Information\n",
      "data type: <dtype: 'float32'>\n",
      "min: 0.0\n",
      "max: 245.6819610595703\n",
      "shape: (10, 184, 216, 1)\n",
      "4/4 [==============================] - 2s 218ms/step\n",
      "10/10 [==============================] - 3s 113ms/step\n"
     ]
    }
   ],
   "source": [
    "noise_dim = 100\n",
    "num_examples_to_generate = batch_size*n\n",
    "\n",
    "def preprocess_prediction(image):\n",
    "#     image = tf.image.grayscale_to_rgb(image)\n",
    "#     image = tf.image.resize(images, (299,299,3))\n",
    "    image = image/2 + 0.5\n",
    "    image *= 255\n",
    "    return image\n",
    "    \n",
    "with tf.device(\"CPU\"):\n",
    "    seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "    predictions = generator(seed, training=False)\n",
    "    generated_images = preprocess_prediction(predictions)\n",
    "    \n",
    "    print_data_info(generated_images, \"Preprocessed Generated Images\")\n",
    "    for image in real_images.take(1):\n",
    "        print_data_info(image, \"Preprocessed Real Images\")\n",
    "    \n",
    "    # calculate features from inception model prediction\n",
    "    generated_features = inception_model.predict(generated_images)\n",
    "    real_features = inception_model.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "648f0f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FID Score: 0.13438224902819698\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def calculate_fid_score(real_features, generated_features):\n",
    "    # Calculate the mean of the real and generated features\n",
    "    mean_real = np.mean(real_features, axis=0)\n",
    "    mean_generated = np.mean(generated_features, axis=0)\n",
    "\n",
    "    # Calculate the covariance matrices of the real and generated features\n",
    "    cov_real = np.cov(real_features, rowvar=False)\n",
    "    cov_generated = np.cov(generated_features, rowvar=False)\n",
    "\n",
    "    # Calculate the squared Euclidean distance between the mean feature vectors\n",
    "    distance = np.sum((mean_real - mean_generated) ** 2)\n",
    "\n",
    "    # Calculate the square root of the product of the covariance matrices\n",
    "    cov_sqrt = sqrtm(cov_real.dot(cov_generated))\n",
    "\n",
    "    # Check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(cov_sqrt):\n",
    "        cov_sqrt = cov_sqrt.real\n",
    "    \n",
    "    # Calculate the FID score\n",
    "    fid_score = distance + np.trace(cov_real + cov_generated - 2 * cov_sqrt)\n",
    "\n",
    "    return fid_score\n",
    "\n",
    "# Calculate the FID score for the generated and real features\n",
    "fid_score = calculate_fid_score(real_features, generated_features)\n",
    "print(\"FID Score:\", fid_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
