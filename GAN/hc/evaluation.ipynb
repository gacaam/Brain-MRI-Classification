{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52fdafb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 07:01:22.097272: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "328c14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(data, obj):\n",
    "    print(f\"\\n{obj} Information\")\n",
    "    print(f\"data type: {data.dtype}\")\n",
    "    print(f\"min: {np.min(data)}\\nmax: {np.max(data)}\")\n",
    "    print(f\"shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "febff2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 07:01:24.099035: I tensorflow/core/platform/cpu_feature_guard.cc:194] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 07:01:24.815223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1637] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7910 MB memory:  -> device: 0, name: A100-SXM4-40GB MIG 2g.10gb, pci bus id: 0000:90:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11900 files belonging to 1 classes.\n",
      "\n",
      "Initial Real Image Information\n",
      "data type: <dtype: 'float32'>\n",
      "min: 0.0\n",
      "max: 247.0\n",
      "shape: (184, 216, 3)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "img_height = 184\n",
    "img_width = 216\n",
    "img_size = (img_height, img_width)\n",
    "img_shape = img_size + (3,)\n",
    "\n",
    "images_path = \"/drive0-storage/Gracia/dataset/hc\"\n",
    "with tf.device(\"CPU\"):\n",
    "    real_images = image_dataset_from_directory(images_path,\n",
    "                                               image_size = img_size,\n",
    "                                               batch_size = batch_size,\n",
    "                                               seed = 123)\n",
    "\n",
    "    for images, labels in real_images.take(1):\n",
    "        for i in range(1):\n",
    "            sample = images[i]\n",
    "            print_data_info(sample, \"Initial Real Image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27783bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def preprocess(image, label):\n",
    "#     image = tf.image.resize(299,299,3)\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    return image\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    real_images = (\n",
    "        real_images\n",
    "        .shuffle(buffer_size = BUFFER_SIZE)\n",
    "        .map(preprocess, num_parallel_calls=AUTOTUNE))\n",
    "    \n",
    "#     n = int(input('number of batch: '))\n",
    "    n = 10\n",
    "    images = real_images.take(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30817756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained InceptionV3 model\n",
    "with tf.device(\"CPU\"):\n",
    "    inception_model = tf.keras.models.load_model('transfer_learning_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a909ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(23*27*512, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((23, 27, 512)))\n",
    "    assert model.output_shape == (None, 23, 27, 512) \n",
    "\n",
    "    model.add(layers.Conv2DTranspose(256, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 46, 54, 256)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 92, 108, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 184, 216, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (4, 4), strides=(1, 1), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 184, 216, 1)\n",
    "\n",
    "    return model\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[184, 216, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    model.add(layers.Conv2D(512, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model\n",
    "\n",
    "with tf.device(\"CPU\"):\n",
    "    generator = make_generator_model()\n",
    "    discriminator = make_discriminator_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d873aa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f26d64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 100\n",
    "num_examples_to_generate = batch_size*n\n",
    "\n",
    "def preprocess_prediction(image):\n",
    "#     image = tf.image.grayscale_to_rgb(image)\n",
    "#     image = tf.image.resize(images, (299,299,3))\n",
    "    image = image/2 + 0.5\n",
    "    image *= 255\n",
    "    return image\n",
    "\n",
    "def get_features():\n",
    "    with tf.device(\"CPU\"):\n",
    "        seed = tf.random.normal([num_examples_to_generate, noise_dim])\n",
    "        predictions = generator(seed, training=False)\n",
    "        generated_images = preprocess_prediction(predictions)\n",
    "\n",
    "#         print_data_info(generated_images, \"Preprocessed Generated Images\")\n",
    "#         for image in real_images.take(1):\n",
    "#             print_data_info(image, \"Preprocessed Real Images\")\n",
    "\n",
    "        # calculate features from inception model prediction\n",
    "        generated_features = inception_model.predict(generated_images)\n",
    "        real_features = inception_model.predict(images)\n",
    "    return generated_features, real_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f28b161b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import sqrtm\n",
    "\n",
    "def calculate_fid_score(real_features, generated_features):\n",
    "    # Calculate the mean of the real and generated features\n",
    "    mean_real = np.mean(real_features, axis=0)\n",
    "    mean_generated = np.mean(generated_features, axis=0)\n",
    "\n",
    "    # Calculate the covariance matrices of the real and generated features\n",
    "    cov_real = np.cov(real_features, rowvar=False)\n",
    "    cov_generated = np.cov(generated_features, rowvar=False)\n",
    "\n",
    "    # Calculate the squared Euclidean distance between the mean feature vectors\n",
    "    distance = np.sum((mean_real - mean_generated) ** 2)\n",
    "\n",
    "    # Calculate the square root of the product of the covariance matrices\n",
    "    cov_sqrt = sqrtm(cov_real.dot(cov_generated))\n",
    "\n",
    "    # Check and correct imaginary numbers from sqrt\n",
    "    if np.iscomplexobj(cov_sqrt):\n",
    "        cov_sqrt = cov_sqrt.real\n",
    "    \n",
    "    # Calculate the FID score\n",
    "    fid_score = distance + np.trace(cov_real + cov_generated - 2 * cov_sqrt)\n",
    "\n",
    "    return fid_score\n",
    "\n",
    "# Calculate the FID score for the generated and real features\n",
    "# fid_score = calculate_fid_score(real_features, generated_features)\n",
    "# print(\"FID Score:\", fid_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55b72a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_specific_checkpoint(index):\n",
    "    ckpt_path = f\"./training_checkpoints/ckpt-{index}\"\n",
    "    checkpoint.restore(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d20f86f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 218ms/step\n",
      "10/10 [==============================] - 3s 113ms/step\n",
      "4/4 [==============================] - 1s 215ms/step\n",
      "10/10 [==============================] - 3s 111ms/step\n",
      "4/4 [==============================] - 1s 213ms/step\n",
      "10/10 [==============================] - 3s 110ms/step\n",
      "4/4 [==============================] - 1s 216ms/step\n",
      "10/10 [==============================] - 2s 112ms/step\n",
      "4/4 [==============================] - 1s 216ms/step\n",
      "10/10 [==============================] - 3s 111ms/step\n",
      "4/4 [==============================] - 1s 215ms/step\n",
      "10/10 [==============================] - 3s 120ms/step\n",
      "4/4 [==============================] - 1s 217ms/step\n",
      "10/10 [==============================] - 3s 111ms/step\n",
      "4/4 [==============================] - 1s 212ms/step\n",
      "10/10 [==============================] - 2s 109ms/step\n",
      "4/4 [==============================] - 1s 214ms/step\n",
      "10/10 [==============================] - 3s 111ms/step\n",
      "4/4 [==============================] - 1s 212ms/step\n",
      "10/10 [==============================] - 2s 109ms/step\n",
      "4/4 [==============================] - 1s 217ms/step\n",
      "10/10 [==============================] - 3s 111ms/step\n",
      "4/4 [==============================] - 1s 214ms/step\n",
      "10/10 [==============================] - 3s 110ms/step\n"
     ]
    }
   ],
   "source": [
    "FID = []\n",
    "epochs = np.arange(300,631,30)\n",
    "\n",
    "for epoch in epochs:\n",
    "    checkpoint_idx = int(epoch/15)\n",
    "    restore_specific_checkpoint(checkpoint_idx)\n",
    "    generated_features, real_features = get_features()\n",
    "    fid_score = calculate_fid_score(real_features, generated_features)\n",
    "    FID.append(fid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f36fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>checkpoint</th>\n",
       "      <th>FID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.122525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>330</td>\n",
       "      <td>22</td>\n",
       "      <td>0.218107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>360</td>\n",
       "      <td>24</td>\n",
       "      <td>0.140852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>390</td>\n",
       "      <td>26</td>\n",
       "      <td>0.132899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>420</td>\n",
       "      <td>28</td>\n",
       "      <td>0.252111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>450</td>\n",
       "      <td>30</td>\n",
       "      <td>0.202109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>480</td>\n",
       "      <td>32</td>\n",
       "      <td>0.093858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>510</td>\n",
       "      <td>34</td>\n",
       "      <td>0.255147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>540</td>\n",
       "      <td>36</td>\n",
       "      <td>0.303069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>570</td>\n",
       "      <td>38</td>\n",
       "      <td>0.186628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>600</td>\n",
       "      <td>40</td>\n",
       "      <td>0.113234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>630</td>\n",
       "      <td>42</td>\n",
       "      <td>0.204905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch  checkpoint       FID\n",
       "0     300          20  0.122525\n",
       "1     330          22  0.218107\n",
       "2     360          24  0.140852\n",
       "3     390          26  0.132899\n",
       "4     420          28  0.252111\n",
       "5     450          30  0.202109\n",
       "6     480          32  0.093858\n",
       "7     510          34  0.255147\n",
       "8     540          36  0.303069\n",
       "9     570          38  0.186628\n",
       "10    600          40  0.113234\n",
       "11    630          42  0.204905"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'epoch' : epochs,\n",
    "                   'checkpoint' : (epochs/15).astype('uint8'),\n",
    "                  'FID' : FID})\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
